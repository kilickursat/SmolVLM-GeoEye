# Complete Streamlit Secrets Configuration
# ==========================================
# Place this in ~/.streamlit/secrets.toml

# RunPod Configuration (REQUIRED for GPU processing)
[runpod]
api_key = "your_runpod_api_key_here"
endpoint_id = "your_runpod_endpoint_id_here"
base_url = "https://api.runpod.ai/v2"  # Default, usually doesn't need to change
timeout = 300  # Request timeout in seconds
max_retries = 3  # Number of retry attempts

# HuggingFace Configuration (RECOMMENDED)
[huggingface]
token = "hf_your_huggingface_token_here"  # Standard HF token format
cache_dir = "/tmp/huggingface_cache"  # Optional: custom cache directory

# Alternative format (also supported)
HF_TOKEN = "hf_your_huggingface_token_here"
RUNPOD_API_KEY = "your_runpod_api_key_here"
RUNPOD_ENDPOINT_ID = "your_runpod_endpoint_id_here"

# Orchestration Configuration (RECOMMENDED for performance)
[orchestration]
max_concurrent_workflows = 5  # Maximum parallel agent executions
workflow_timeout_minutes = 10  # Timeout for complete workflows
parallel_agent_execution = true  # Enable parallel processing
agent_retry_attempts = 2  # Retry failed agent calls
cache_agent_responses = true  # Cache responses for 1 hour

# Processing Configuration (OPTIONAL tuning)
[processing]
enable_async_processing = true  # Allow async/sync mode selection
max_upload_size_mb = 200  # Maximum file upload size
image_max_dimension = 1536  # Maximum image dimension for processing
batch_processing = true  # Enable batch document processing
compression_enabled = true  # Enable response compression

# Performance Optimization (ADVANCED)
[performance]
enable_caching = true  # Enable response caching
cache_ttl_minutes = 60  # Cache time-to-live
enable_streaming = true  # Enable streaming responses
connection_pool_size = 10  # HTTP connection pool size
request_timeout = 300  # Individual request timeout

# Security Configuration (PRODUCTION)
[security]
enable_rate_limiting = true  # Enable request rate limiting
max_requests_per_minute = 100  # Rate limit threshold
enable_request_logging = true  # Log all API requests
sanitize_uploads = true  # Sanitize uploaded files

# Monitoring Configuration (OPTIONAL)
[monitoring]
enable_metrics = true  # Enable performance metrics
log_level = "INFO"  # Logging level: DEBUG, INFO, WARNING, ERROR
enable_health_checks = true  # Enable endpoint health monitoring
metrics_export_interval = 60  # Metrics export interval in seconds

# Environment Configuration
[environment]
debug_mode = false  # Enable debug mode
environment = "production"  # Environment: development, staging, production
enable_experimental_features = false  # Enable beta features

# Cost Optimization (RECOMMENDED)
[cost_optimization]
auto_scale_workers = true  # Enable auto-scaling
min_workers = 0  # Minimum workers (0 for cost optimization)
max_workers = 10  # Maximum workers
idle_timeout_seconds = 5  # Worker idle timeout
enable_flash_boot = true  # Enable FlashBoot for faster startups

# Agent Configuration (ADVANCED)
[agents]
data_processor_enabled = true  # Enable soil data analysis agent
engineering_analyst_enabled = true  # Enable tunnel/safety agent
vision_agent_enabled = true  # Enable RunPod vision agent
agent_timeout_seconds = 120  # Individual agent timeout
enable_agent_fallbacks = true  # Enable fallback responses

# Database Configuration (OPTIONAL - for future features)
[database]
# enable_persistence = false
# connection_string = "postgresql://user:pass@localhost/geotechnical"
# connection_pool_size = 5

# External APIs (OPTIONAL - for integrations)
[external_apis]
# openai_api_key = "sk-your-openai-key"  # For GPT integration
# anthropic_api_key = "your-anthropic-key"  # For Claude integration
# google_api_key = "your-google-key"  # For Google services

# Notification Configuration (OPTIONAL)
[notifications]
# enable_email_alerts = false
# smtp_server = "smtp.gmail.com"
# smtp_port = 587
# email_user = "your-email@domain.com"
# email_password = "your-app-password"
# slack_webhook_url = "https://hooks.slack.com/your-webhook"

# Custom Model Configuration (ADVANCED)
[custom_models]
# Enable if you want to use different models
default_vision_model = "HuggingFaceTB/SmolVLM-Instruct"
# alternative_models = ["microsoft/Florence-2-large", "Salesforce/blip2-opt-2.7b"]
model_cache_enabled = true
model_load_timeout = 300

# Regional Configuration (OPTIONAL)
[regional]
# preferred_region = "us-east-1"  # Preferred RunPod region
# fallback_regions = ["us-west-1", "eu-west-1"]
# timezone = "UTC"
# locale = "en_US"

# Feature Flags (EXPERIMENTAL)
[feature_flags]
enable_3d_visualization = false  # 3D visualization features
enable_real_time_collaboration = false  # Real-time collaboration
enable_advanced_analytics = true  # Advanced analytics features
enable_export_to_cad = false  # CAD export functionality
enable_ai_recommendations = true  # AI-powered recommendations
